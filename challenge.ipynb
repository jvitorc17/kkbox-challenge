{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "216be500-721f-45ac-ab63-6b0b67ec5fb9",
    "_uuid": "c8542907ead88c658cfe43c79118b30fc19487bf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "91dfcb80-f6a5-48b8-b889-2b4df0e4a4e1",
    "_uuid": "81f223f194c6f6f8fb54b908a434a527a3f66c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Done loading...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "data_path = 'input/'\n",
    "train = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                  'source_screen_name' : 'category',\n",
    "                                                  'source_type' : 'category',\n",
    "                                                  'target' : np.uint8,\n",
    "                                                  'song_id' : 'category'})\n",
    "test = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n",
    "                                                'source_system_tab' : 'category',\n",
    "                                                'source_screen_name' : 'category',\n",
    "                                                'source_type' : 'category',\n",
    "                                                'song_id' : 'category'})\n",
    "songs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n",
    "                                                  'language' : 'category',\n",
    "                                                  'artist_name' : 'category',\n",
    "                                                  'composer' : 'category',\n",
    "                                                  'lyricist' : 'category',\n",
    "                                                  'song_id' : 'category'})\n",
    "members = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n",
    "                                                      'bd' : np.uint8,\n",
    "                                                      'gender' : 'category',\n",
    "                                                      'registered_via' : 'category'},\n",
    "                     parse_dates=['registration_init_time','expiration_date'])\n",
    "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\n",
    "print('Done loading...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging train and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merging...\n"
     ]
    }
   ],
   "source": [
    "print('Data merging...')\n",
    "\n",
    "train = train.merge(songs, on='song_id', how='left')\n",
    "test = test.merge(songs, on='song_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n",
    "\n",
    "members['registration_year'] = members['registration_init_time'].dt.year\n",
    "members['registration_month'] = members['registration_init_time'].dt.month\n",
    "members['registration_date'] = members['registration_init_time'].dt.day\n",
    "\n",
    "members['expiration_year'] = members['expiration_date'].dt.year\n",
    "members['expiration_month'] = members['expiration_date'].dt.month\n",
    "members['expiration_date'] = members['expiration_date'].dt.day\n",
    "members = members.drop(['registration_init_time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting year of the music from isrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n",
    "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging remain datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "24e253c9-b8f8-4c56-b1a5-5faa9bb17c8d",
    "_uuid": "95fae49636554eeb26dde3370054fbf6788335a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done merging...\n"
     ]
    }
   ],
   "source": [
    "train = train.merge(members, on='msno', how='left')\n",
    "test = test.merge(members, on='msno', how='left')\n",
    "\n",
    "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "train.song_length.fillna(200000,inplace=True)\n",
    "train.song_length = train.song_length.astype(np.uint32)\n",
    "train.song_id = train.song_id.astype('category')\n",
    "\n",
    "\n",
    "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n",
    "test.song_length.fillna(200000,inplace=True)\n",
    "test.song_length = test.song_length.astype(np.uint32)\n",
    "test.song_id = test.song_id.astype('category')\n",
    "\n",
    "print('Done merging...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_id_count(x):\n",
    "    if x == 'no_genre_id':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('|') + 1\n",
    "\n",
    "train['genre_ids'] = train['genre_ids'].cat.add_categories(['no_genre_id'])\n",
    "test['genre_ids'] = test['genre_ids'].cat.add_categories(['no_genre_id'])\n",
    "train['genre_ids'].fillna('no_genre_id',inplace=True)\n",
    "test['genre_ids'].fillna('no_genre_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count)\n",
    "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyricist_count(x):\n",
    "    if x == 'no_lyricist':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n",
    "\n",
    "train['lyricist'] = train['lyricist'].cat.add_categories(['no_lyricist'])\n",
    "test['lyricist'] = test['lyricist'].cat.add_categories(['no_lyricist'])\n",
    "\n",
    "train['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "test['lyricist'].fillna('no_lyricist',inplace=True)\n",
    "train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composer_count(x):\n",
    "    if x == 'no_composer':\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n",
    "\n",
    "train['composer'] = train['composer'].cat.add_categories(['no_composer'])\n",
    "test['composer'] = test['composer'].cat.add_categories(['no_composer'])    \n",
    "    \n",
    "train['composer'].fillna('no_composer',inplace=True)\n",
    "test['composer'].fillna('no_composer',inplace=True)\n",
    "train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n",
    "test['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "train['artist_name'] = train['artist_name'].cat.add_categories(['no_artist'])\n",
    "test['artist_name'] = test['artist_name'].cat.add_categories(['no_artist'])  \n",
    "\n",
    "train['artist_name'].fillna('no_artist',inplace=True)\n",
    "test['artist_name'].fillna('no_artist',inplace=True)\n",
    "train['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "test['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_count(x):\n",
    "    if x == 'no_artist':\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n",
    "\n",
    "train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n",
    "test['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if artist is same as composer\n",
    "train['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\n",
    "test['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Categoricals can only be compared if 'categories' are the same. Categories are different lengths",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-33ae09e17987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'artist_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'composer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0;31m# Dispatch to Categorical implementation; pd.CategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;31m# behavior is non-canonical GH#19513\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_to_index_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m             return self._constructor(res_values, index=self.index,\n\u001b[1;32m   1198\u001b[0m                                      name=res_name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mdispatch_to_index_op\u001b[0;34m(op, left, right, index_class)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mleft_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNullFrequencyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1194\u001b[0m             \u001b[0;31m# Dispatch to Categorical implementation; pd.CategoricalIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;31m# behavior is non-canonical GH#19513\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_to_index_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m             return self._constructor(res_values, index=self.index,\n\u001b[1;32m   1198\u001b[0m                                      name=res_name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mdispatch_to_index_op\u001b[0;34m(op, left, right, index_class)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0mleft_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shallow_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNullFrequencyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# DatetimeIndex and TimedeltaIndex with freq == None raise ValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     82\u001b[0m                    \"'categories' are the same.\")\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Categories are different lengths\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             elif (self.ordered and not (self.categories ==\n\u001b[1;32m     86\u001b[0m                                         other.categories).all()):\n",
      "\u001b[0;31mTypeError\u001b[0m: Categoricals can only be compared if 'categories' are the same. Categories are different lengths"
     ]
    }
   ],
   "source": [
    "train['artist_name'] == train['composer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6d0e7314-91f0-4ff5-9081-ebdcb9b1406d",
    "_uuid": "2f5475aa07fa7f4b59e8e8928d03f67bbcac9347"
   },
   "source": [
    "print (\"Adding new features\")\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "train['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\n",
    "test['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n",
    "\n",
    "# is song language 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "test['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "\n",
    "_mean_song_length = np.mean(train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\n",
    "test['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n",
    "\n",
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n",
    "_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_song_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "train['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\n",
    "test['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n",
    "_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            return _dict_count_artist_played_test[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "train['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "test['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "\n",
    "\n",
    "print(\"Done adding features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "05ee917e-dc12-4201-8fe6-0b515286253c",
    "_uuid": "577e8f31dccc7262514f854b96bb213396aea8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test and validation sets\n",
      "Processed data...\n"
     ]
    }
   ],
   "source": [
    "print (\"Train test and validation sets\")\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == object:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "\n",
    "X_train = train.drop(['target'], axis=1)\n",
    "y_train = train['target'].values\n",
    "\n",
    "\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "ids = test['id'].values\n",
    "\n",
    "\n",
    "d_train_final = lgb.Dataset(X_train, y_train)\n",
    "watchlist_final = lgb.Dataset(X_train, y_train)\n",
    "print('Processed data...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "8a7cfb94-afdb-47b1-94d7-88791baa47e5",
    "_uuid": "42e044686bd89948d06c2471892c9542605a8a05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:113: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/joao/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:742: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.720951\n",
      "[10]\tvalid_0's auc: 0.735892\n",
      "[15]\tvalid_0's auc: 0.743342\n",
      "[20]\tvalid_0's auc: 0.748352\n",
      "[25]\tvalid_0's auc: 0.752787\n",
      "[30]\tvalid_0's auc: 0.755986\n",
      "[35]\tvalid_0's auc: 0.758878\n",
      "[40]\tvalid_0's auc: 0.761747\n",
      "[45]\tvalid_0's auc: 0.764294\n",
      "[50]\tvalid_0's auc: 0.766708\n",
      "[55]\tvalid_0's auc: 0.768616\n",
      "[60]\tvalid_0's auc: 0.770675\n",
      "[65]\tvalid_0's auc: 0.772564\n",
      "[70]\tvalid_0's auc: 0.77455\n",
      "[75]\tvalid_0's auc: 0.776301\n",
      "[80]\tvalid_0's auc: 0.777782\n",
      "[85]\tvalid_0's auc: 0.77895\n",
      "[90]\tvalid_0's auc: 0.780336\n",
      "[95]\tvalid_0's auc: 0.781561\n",
      "[100]\tvalid_0's auc: 0.782774\n",
      "[105]\tvalid_0's auc: 0.783975\n",
      "[110]\tvalid_0's auc: 0.785055\n",
      "[115]\tvalid_0's auc: 0.786174\n",
      "[120]\tvalid_0's auc: 0.787242\n",
      "[125]\tvalid_0's auc: 0.78871\n",
      "[130]\tvalid_0's auc: 0.789762\n",
      "[135]\tvalid_0's auc: 0.791192\n",
      "[140]\tvalid_0's auc: 0.792167\n",
      "[145]\tvalid_0's auc: 0.79291\n",
      "[150]\tvalid_0's auc: 0.79449\n",
      "[155]\tvalid_0's auc: 0.795391\n",
      "[160]\tvalid_0's auc: 0.796227\n",
      "[165]\tvalid_0's auc: 0.797608\n",
      "[170]\tvalid_0's auc: 0.798361\n",
      "[175]\tvalid_0's auc: 0.799182\n",
      "[180]\tvalid_0's auc: 0.800056\n",
      "[185]\tvalid_0's auc: 0.800681\n",
      "[190]\tvalid_0's auc: 0.801216\n",
      "[195]\tvalid_0's auc: 0.801867\n",
      "[200]\tvalid_0's auc: 0.80225\n",
      "CPU times: user 48min 29s, sys: 41.5 s, total: 49min 10s\n",
      "Wall time: 7min 55s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "10895c7a-73f8-45a0-a9b7-e4e489b06268",
    "_uuid": "a2e8293a6c5ff0c0efdb52fb82f053cfb773e55c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.720951\n",
      "[10]\tvalid_0's auc: 0.734028\n",
      "[15]\tvalid_0's auc: 0.740547\n",
      "[20]\tvalid_0's auc: 0.745759\n",
      "[25]\tvalid_0's auc: 0.750017\n",
      "[30]\tvalid_0's auc: 0.752448\n",
      "[35]\tvalid_0's auc: 0.754569\n",
      "[40]\tvalid_0's auc: 0.757201\n",
      "[45]\tvalid_0's auc: 0.759645\n",
      "[50]\tvalid_0's auc: 0.76078\n",
      "[55]\tvalid_0's auc: 0.76421\n",
      "[60]\tvalid_0's auc: 0.765976\n",
      "[65]\tvalid_0's auc: 0.767258\n",
      "[70]\tvalid_0's auc: 0.769022\n",
      "[75]\tvalid_0's auc: 0.770298\n",
      "[80]\tvalid_0's auc: 0.771426\n",
      "[85]\tvalid_0's auc: 0.771402\n",
      "[90]\tvalid_0's auc: 0.771706\n",
      "[95]\tvalid_0's auc: 0.772173\n",
      "[100]\tvalid_0's auc: 0.772576\n",
      "[105]\tvalid_0's auc: 0.772691\n",
      "[110]\tvalid_0's auc: 0.772866\n",
      "[115]\tvalid_0's auc: 0.774864\n",
      "[120]\tvalid_0's auc: 0.775801\n",
      "[125]\tvalid_0's auc: 0.776462\n",
      "[130]\tvalid_0's auc: 0.777561\n",
      "[135]\tvalid_0's auc: 0.778437\n",
      "[140]\tvalid_0's auc: 0.779192\n",
      "[145]\tvalid_0's auc: 0.779845\n",
      "[150]\tvalid_0's auc: 0.780467\n",
      "[155]\tvalid_0's auc: 0.780515\n",
      "[160]\tvalid_0's auc: 0.779834\n",
      "[165]\tvalid_0's auc: 0.780753\n",
      "[170]\tvalid_0's auc: 0.781726\n",
      "[175]\tvalid_0's auc: 0.782748\n",
      "[180]\tvalid_0's auc: 0.782583\n",
      "[185]\tvalid_0's auc: 0.783702\n",
      "[190]\tvalid_0's auc: 0.784132\n",
      "[195]\tvalid_0's auc: 0.784685\n",
      "[200]\tvalid_0's auc: 0.784584\n",
      "CPU times: user 2h 39min 30s, sys: 57 s, total: 2h 40min 27s\n",
      "Wall time: 22min 55s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'dart',\n",
    "        'learning_rate': 0.3 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 200,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 0.723729\n",
      "[10]\tvalid_0's auc: 0.739205\n",
      "[15]\tvalid_0's auc: 0.746846\n",
      "[20]\tvalid_0's auc: 0.752161\n",
      "[25]\tvalid_0's auc: 0.757114\n",
      "[30]\tvalid_0's auc: 0.760884\n",
      "[35]\tvalid_0's auc: 0.764447\n",
      "[40]\tvalid_0's auc: 0.767514\n",
      "[45]\tvalid_0's auc: 0.770833\n",
      "[50]\tvalid_0's auc: 0.773266\n",
      "[55]\tvalid_0's auc: 0.775311\n",
      "[60]\tvalid_0's auc: 0.77757\n",
      "[65]\tvalid_0's auc: 0.779417\n",
      "[70]\tvalid_0's auc: 0.781149\n",
      "[75]\tvalid_0's auc: 0.782635\n",
      "[80]\tvalid_0's auc: 0.784085\n",
      "[85]\tvalid_0's auc: 0.786266\n",
      "[90]\tvalid_0's auc: 0.78741\n",
      "[95]\tvalid_0's auc: 0.788687\n",
      "[100]\tvalid_0's auc: 0.789852\n",
      "[105]\tvalid_0's auc: 0.791132\n",
      "[110]\tvalid_0's auc: 0.792272\n",
      "[115]\tvalid_0's auc: 0.793334\n",
      "[120]\tvalid_0's auc: 0.79478\n",
      "[125]\tvalid_0's auc: 0.796126\n",
      "[130]\tvalid_0's auc: 0.797103\n",
      "[135]\tvalid_0's auc: 0.798319\n",
      "[140]\tvalid_0's auc: 0.799268\n",
      "[145]\tvalid_0's auc: 0.800811\n",
      "[150]\tvalid_0's auc: 0.802055\n",
      "[155]\tvalid_0's auc: 0.80265\n",
      "[160]\tvalid_0's auc: 0.803421\n",
      "[165]\tvalid_0's auc: 0.804306\n",
      "[170]\tvalid_0's auc: 0.805373\n",
      "[175]\tvalid_0's auc: 0.806217\n",
      "[180]\tvalid_0's auc: 0.806958\n",
      "[185]\tvalid_0's auc: 0.808028\n",
      "[190]\tvalid_0's auc: 0.808545\n",
      "[195]\tvalid_0's auc: 0.809354\n",
      "[200]\tvalid_0's auc: 0.809886\n",
      "[205]\tvalid_0's auc: 0.810542\n",
      "[210]\tvalid_0's auc: 0.811299\n",
      "[215]\tvalid_0's auc: 0.811941\n",
      "[220]\tvalid_0's auc: 0.81262\n",
      "[225]\tvalid_0's auc: 0.813554\n",
      "[230]\tvalid_0's auc: 0.814662\n",
      "[235]\tvalid_0's auc: 0.815559\n",
      "[240]\tvalid_0's auc: 0.816044\n",
      "[245]\tvalid_0's auc: 0.816446\n",
      "[250]\tvalid_0's auc: 0.817029\n",
      "CPU times: user 57min 11s, sys: 32.9 s, total: 57min 43s\n",
      "Wall time: 9min 7s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.4 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 108,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 0.9,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 256,\n",
    "        'max_depth': 10,\n",
    "        'num_rounds': 250,\n",
    "        'metric' : 'auc'\n",
    "    }\n",
    "\n",
    "%time model_f3 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "89048be8-a137-4e0d-811c-740645c17d1a",
    "_uuid": "ea33e6b678757c4f45e1cddfac4a37ce06962d33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "Done making predictions\n"
     ]
    }
   ],
   "source": [
    "print('Making predictions')\n",
    "p_test_1 = model_f1.predict(X_test)\n",
    "p_test_2 = model_f2.predict(X_test)\n",
    "p_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n",
    "\n",
    "\n",
    "print('Done making predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_3 = model_f3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test_3\n",
    "subm.to_csv('submissions/' + 'submission_lgbm_new_parameters.csv', index=False, float_format = '%.5f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "e7b31f60-187f-4744-9416-3c9c876fa838",
    "_uuid": "28888fb62a1efccb51efb762ac1266695bb82002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions Model model of gbdt\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print ('Saving predictions Model model of gbdt')\n",
    "\n",
    "subm = pd.DataFrame()\n",
    "subm['id'] = ids\n",
    "subm['target'] = p_test_avg\n",
    "subm.to_csv('submissions/' + 'submission_lgbm_avg.csv', index=False, float_format = '%.5f')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('submissions/submission_lgbm_new_parameters.csv')\n",
    "d2 = pd.read_csv('submissions/submission_lgbm_avg.csv')\n",
    "\n",
    "p_test_avg_3 = np.mean([d1['target'].values, d2['target'].values], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.DataFrame()\n",
    "s['id'] = d1['id']\n",
    "s['target'] = p_test_avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.to_csv('submissions/'+'submission_lgbm_avg_between_others.csv', index=False, float_format = '%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
